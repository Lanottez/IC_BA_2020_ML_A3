{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "\n",
    "data_path = \"./\"\n",
    "\n",
    "# 1. loads the data file;\n",
    "training_data = pd.read_csv(data_path + 'training.csv') \n",
    "validation_data = pd.read_csv(data_path + 'validation.csv')\n",
    "test1_data = pd.read_csv(data_path + 'test1.csv') \n",
    "test2_data = pd.read_csv(data_path + 'test2.csv') \n",
    "\n",
    "# 2. load txt file\n",
    "text_file = open('censored_list_test1.txt', 'r')\n",
    "list_censored_test1 = text_file.read().split()\n",
    "text_file.close()\n",
    "\n",
    "text_file = open('censored_list_test2.txt', 'r')\n",
    "list_censored_test2 = text_file.read().split()\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-6ef78ecaf35c>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  col= col.str.replace('\\d+', ' ')\n",
      "<ipython-input-4-6ef78ecaf35c>:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  col = col.str.replace('[^\\w\\s]',' ')\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "\n",
    "def cleaning_sms(col):\n",
    "    # convert to lower-case\n",
    "    col = col.str.lower()\n",
    "    #remove digits\n",
    "    col= col.str.replace('\\d+', ' ')\n",
    "    #remove punctuation\n",
    "    col = col.str.replace('[^\\w\\s]',' ')\n",
    "    return col\n",
    "\n",
    "training_data[\"sms\"] = cleaning_sms(training_data[\"sms\"])\n",
    "validation_data[\"sms\"] = cleaning_sms(validation_data[\"sms\"])\n",
    "test1_data[\"sms\"]= cleaning_sms(test1_data[\"sms\"])\n",
    "test2_data[\"sms\"] = cleaning_sms(test2_data[\"sms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "\n",
    "class NaiveBayesForSpam:\n",
    "#These two functions trains the  Naive Bayes classifier, i.e get the labeled SMS(messages for which we know whether they're spam or ham), \n",
    "#iterate over each individual message and identify\n",
    "\n",
    "    def train (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "        \n",
    "    def train2 (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        spamkeywords = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            if prob1 * 20 < prob2:\n",
    "                self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "                spamkeywords.append (w)\n",
    "        self.words = spamkeywords\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "\n",
    "#Returning predictions, bayes's theorem is applied in this function \n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    "        for i, w in enumerate (self.words):\n",
    "            if w in message.lower():  # convert to lower-case\n",
    "                posteriors *= self.likelihoods[:,i]\n",
    "            else:                                   \n",
    "                posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "            posteriors = posteriors / np.linalg.norm (posteriors)  # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]    \n",
    "\n",
    "#Calcauting accuracy score and confusion matrix of the classifiers\n",
    "    def score (self, messages, labels):\n",
    "        ## | TP | FP |\n",
    "        ## | FN | TN |\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "#### The functions  above are used to calculate prior probability based on Bayes theorem\n",
    "__train function__ \n",
    "* creates a set of all the words present in the spam and ham messages\n",
    "* calculates the frequency with each word is present in a sentence, this frequency represents the ratio of the times a spam/ham message contains such words. It is noted that this ratio is restricted to be lower than 0.95\n",
    "\n",
    "__train2 function__\n",
    " the function performs the same procedures as train 1 with the following differences\n",
    "* In train2 function a new list is generated named \"spamkeywords\", which contains letters with high probability to appear in spamMessage, actually those that appear more than 20 times more often in spam than in ham messages\n",
    "* Also, the prior probability(likelihood function) only contains the letters with high probability\n",
    "\n",
    "__predict function__\n",
    "* Initially all the words in message are converted to lower case \n",
    "* Then the function uses the naives bayes method to calculate the posterior probability as a proportion of likelihood and prior probability\n",
    "* After performing a normalisation, to deal with computational issues, the message is categorised as  spam or ham according to the value of the posterior probability calculated\n",
    "\n",
    "\n",
    "__score function__\n",
    "* The function aggregates the number the messages based on whether they have been categorised correctly or wrongly . Essentialy it calculates and returns the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5\n",
    "training_ham = list(training_data[training_data.label =='ham'].sms)\n",
    "training_spam = list(training_data[training_data.label =='spam'].sms)\n",
    "\n",
    "naive_bayes_training1=NaiveBayesForSpam()\n",
    "naive_bayes_training1.train(training_ham,training_spam)\n",
    "\n",
    "naive_bayes_training2=NaiveBayesForSpam()\n",
    "naive_bayes_training2.train2(training_ham,training_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.958,\n",
       " array([[857.,  35.],\n",
       "        [  3., 105.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 6\n",
    "confusion_matrix1 = naive_bayes_training1.score(validation_data.sms, validation_data.label)\n",
    "confusion_matrix2 = naive_bayes_training2.score(validation_data.sms, validation_data.label)\n",
    "\n",
    "confusion_matrix1[0], confusion_matrix2[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "\n",
    "The train2 is faster because it uses far less words in order to calculate the posterior probability, consequently the list of words we are comparing eacg word in the validation set is way shorter and far less calculations are taking place, for example comparisons and multiplications. \n",
    "\n",
    "The train2 is more accurate because it uses words that are 20+ times more often present more in spam than in ham messages. Consequently it is more probable to be more important than the classifiers that are ignored. \n",
    "Those \"non-important\" classifier might be misleading as it may cause noise. \n",
    "## ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8\n",
    "false_positives2 = confusion_matrix2[1][0][1]\n",
    "false_positives2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 35 false positives under when using the train2 function.\n",
    "\n",
    "In order to reduce the number of false positives at the expense of flase negatives we could decrease the limit at the threshold in the last part of  \"predict\" function at the line \"if posteriors[0] > 0.5:\" from 0.5 to a smaller number.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9\n",
    "we need to remove missing data list when predicting. \n",
    "i.e. for all items from censored_test file, remove it from classifier list when doing predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesForSpam_updatedby_censored1:\n",
    "#These two functions trains the  Naive Bayes classifier, i.e get the labeled SMS(messages for which we know whether they're spam or ham), \n",
    "#iterate over each individual message and identify\n",
    "\n",
    "    def train (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "        \n",
    "    def train2 (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        spamkeywords = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            if prob1 * 20 < prob2:\n",
    "                self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "                spamkeywords.append (w)\n",
    "        self.words = spamkeywords\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "\n",
    "#Returning predictions, bayes's theorem is applied in this function \n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    " #       self.words_updated=self.words-set(list_censored_test1.words)\n",
    "        for i, w in enumerate (self.words):\n",
    "            if w not in list_censored_test1.words:\n",
    "                if w in message.lower():  # convert to lower-case\n",
    "                    posteriors *= self.likelihoods[:,i]\n",
    "                else:                                   \n",
    "                    posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "                posteriors = posteriors / np.linalg.norm (posteriors)  # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]    \n",
    "\n",
    "#Calcauting accuracy score and confusion matrix of the classifiers\n",
    "    def score (self, messages, labels):\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion\n",
    "    \n",
    "    \n",
    "\n",
    "class NaiveBayesForSpam_updatedby_censored2:\n",
    "#These two functions trains the  Naive Bayes classifier, i.e get the labeled SMS(messages for which we know whether they're spam or ham), \n",
    "#iterate over each individual message and identify\n",
    "\n",
    "    def train (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "        \n",
    "    def train2 (self, hamMessages, spamMessages):\n",
    "        self.words = set (' '.join (hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (hamMessages)) / (len (hamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        spamkeywords = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in hamMessages if w in m])) / len (hamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            if prob1 * 20 < prob2:\n",
    "                self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "                spamkeywords.append (w)\n",
    "        self.words = spamkeywords\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "\n",
    "#Returning predictions, bayes's theorem is applied in this function \n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    "  #      self.words_updated=self.words-set(list_censored_test2.words)\n",
    "        for i, w in enumerate (self.words):\n",
    "            if w not in list_censored_test2.words:\n",
    "                if w in message.lower():  # convert to lower-case\n",
    "                    posteriors *= self.likelihoods[:,i]\n",
    "                else:                                   \n",
    "                    posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "                posteriors = posteriors / np.linalg.norm (posteriors)  # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]    \n",
    "\n",
    "#Calcauting accuracy score and confusion matrix of the classifiers\n",
    "    def score (self, messages, labels):\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10\n",
    "#test1:\n",
    "NaiveByes_test1_censored1=NaiveBayesForSpam_updatedby_censored1()\n",
    "NaiveByes_test1_censored1.train(training_ham,training_spam)\n",
    "validation_matrix_test1_censored1=NaiveByes_test1_censored1.score(validation.sms,validation.label)\n",
    "\n",
    "#test2:\n",
    "NaiveByes_test2_censored1=NaiveBayesForSpam_updatedby_censored1()\n",
    "NaiveByes_test2_censored1.train(training_ham,training_spam)\n",
    "validation_matrix_test2_censored1=NaiveByes_test2_censored1.score(validation.sms,validation.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11\n",
    "\n",
    "#test1:\n",
    "NaiveByes_test1_censored2=NaiveBayesForSpam_updatedby_censored2()\n",
    "NaiveByes_test1_censored2.train(training_ham,training_spam)\n",
    "validation_matrix_test1_censored2=NaiveByes_test1_censored2.score(validation.sms,validation.label)\n",
    "\n",
    "#test2:\n",
    "NaiveByes_test2_censored2=NaiveBayesForSpam_updatedby_censored2()\n",
    "NaiveByes_test2_censored2.train(training_ham,training_spam)\n",
    "validation_matrix_test2_censored2=NaiveByes_test2_censored2.score(validation.sms,validation.label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
